<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8" />
    <title>Brain Portfolio</title>
    
    <script type="importmap">
        {
          "imports": {
            "three": "https://cdn.jsdelivr.net/npm/three@0.160.0/build/three.module.js",
            "three/examples/jsm/loaders/GLTFLoader.js": "https://cdn.jsdelivr.net/npm/three@0.160.0/examples/jsm/loaders/GLTFLoader.js",
            "three/examples/jsm/controls/OrbitControls.js": "https://cdn.jsdelivr.net/npm/three@0.160.0/examples/jsm/controls/OrbitControls.js",
            "three/examples/jsm/renderers/CSS2DRenderer.js": "https://cdn.jsdelivr.net/npm/three@0.160.0/examples/jsm/renderers/CSS2DRenderer.js"
          }
        }
    </script>

    <link rel="stylesheet" href="css/style.css">

</head>
<body>

<div id="expanded-project" class="expanded-card">
    <div class="close-button" onclick="closeExpandedCard()">&times;</div>
    <div id="expanded-content">
        </div>
</div>

<div id="ui-menu">
    <button data-target="OVERVIEW">Home</button>
    <button data-target="ABOUT">About</button>
    <button data-target="PROJECTS">Projects</button>
    <button data-target="CONTACT">Contact</button>
</div>

<script type="module">
    // 1. Imports
    import * as THREE from 'three'; 
    import { GLTFLoader } from 'three/examples/jsm/loaders/GLTFLoader.js';
    import { OrbitControls } from 'three/examples/jsm/controls/OrbitControls.js';
    import { CSS2DRenderer, CSS2DObject } from 'three/examples/jsm/renderers/CSS2DRenderer.js';

    // Import data including the new PROJECT_DETAILS lookup table
    import { CAMERA_POSITIONS, LERP_FACTOR, BRAIN_SCALE, PROJECT_DETAILS } from './js/data.js';

    // Global variables
    let brain;
    let time = 0; 
    let contentObject; 
    let contentElement; 
    let starField;     
    let neuralLines;   
    let dataProbeObject; 

    // State for cinematic navigation
    let currentSection = 'OVERVIEW'; 
    let currentTarget = CAMERA_POSITIONS.OVERVIEW;
    let transitionInProgress = false;
    const DATA_PROBE_DELAY = 1000; // Time (ms) to simulate data processing
    
    // Pulse animation settings (simplified pulse via scale)
    let pulseFactor = 0.0;
    const PULSE_SPEED = 0.05;
    const PULSE_MAGNITUDE = 0.03; // Max scale change during transition

    // --- 2. Setup Scene, Camera, and Renderers ---
    const scene = new THREE.Scene();
    scene.background = new THREE.Color(0x0a0a0a); 
    scene.fog = new THREE.Fog(scene.background, 5, 20); 

    const camera = new THREE.PerspectiveCamera(60, window.innerWidth / window.innerHeight, 0.1, 1000);
    camera.position.copy(currentTarget.pos); 

    // Standard WebGL Renderer
    const renderer = new THREE.WebGLRenderer({ antialias: true });
    renderer.setSize(window.innerWidth, window.innerHeight);
    renderer.setPixelRatio(window.devicePixelRatio);
    document.body.appendChild(renderer.domElement);
    
    // CSS 2D Renderer Setup
    const labelRenderer = new CSS2DRenderer();
    labelRenderer.setSize(window.innerWidth, window.innerHeight);
    labelRenderer.domElement.style.position = 'absolute';
    labelRenderer.domElement.style.top = '0px';
    labelRenderer.domElement.style.pointerEvents = 'none'; 
    document.body.insertBefore(labelRenderer.domElement, document.getElementById('ui-menu').nextSibling); 

    // 3. Setup Controls
    const controls = new OrbitControls(camera, renderer.domElement);
    controls.enableDamping = true; 
    controls.dampingFactor = 0.05;
    controls.target.copy(currentTarget.target);

    // --- 4. Lights ---
    scene.add(new THREE.AmbientLight(0x404040, 1.0)); 
    const keyLight = new THREE.DirectionalLight(0x99ccff, 3.5); 
    keyLight.position.set(5, 5, 5).normalize();
    scene.add(keyLight);
    const rimLight = new THREE.DirectionalLight(0xffaa44, 1.5); 
    rimLight.position.set(-5, -5, -5).normalize();
    scene.add(rimLight);
    
    // --- 5. Starfield Generation (Unchanged) ---
    function createStarfield(count = 30000) {
        const starGeometry = new THREE.BufferGeometry();
        const positions = [];
        const starColor = 0xffffff; 

        for (let i = 0; i < count; i++) {
            const distance = 150 + Math.random() * 200; 
            const theta = THREE.MathUtils.randFloatSpread(360) * (Math.PI / 180);
            const phi = THREE.MathUtils.randFloatSpread(180) * (Math.PI / 180);

            positions.push(
                distance * Math.sin(theta) * Math.cos(phi),
                distance * Math.sin(theta) * Math.sin(phi),
                distance * Math.cos(theta)
            );
        }

        starGeometry.setAttribute('position', new THREE.Float32BufferAttribute(positions, 3));

        const starMaterial = new THREE.PointsMaterial({
            color: starColor,
            size: 0.15, 
            sizeAttenuation: true 
        });

        const starField = new THREE.Points(starGeometry, starMaterial);
        scene.add(starField);
        return starField;
    }

    // --- 6. Neural Network Generation (Unchanged) ---
    function createNeuralNetwork(lineCount = 500) {
        const lines = new THREE.Group();
        const material = new THREE.LineBasicMaterial({
            color: 0x66ccff, 
            transparent: true,
            opacity: 0.1,    
            linewidth: 1
        });

        for (let i = 0; i < lineCount; i++) {
            const geometry = new THREE.BufferGeometry();
            const positions = [];

            const p1 = new THREE.Vector3().setFromSphericalCoords(
                THREE.MathUtils.randFloat(50, 100), 
                THREE.MathUtils.randFloatSpread(360) * (Math.PI / 180), 
                THREE.MathUtils.randFloatSpread(180) * (Math.PI / 180)
            );

            const p2 = new THREE.Vector3().setFromSphericalCoords(
                THREE.MathUtils.randFloat(50, 100), 
                THREE.MathUtils.randFloatSpread(360) * (Math.PI / 180), 
                THREE.MathUtils.randFloatSpread(180) * (Math.PI / 180) 
            );

            positions.push(p1.x, p1.y, p1.z);
            positions.push(p2.x, p2.y, p2.z);

            geometry.setAttribute('position', new THREE.Float32BufferAttribute(positions, 3));
            
            const line = new THREE.Line(geometry, material);
            line.userData.pulse = Math.random() * Math.PI * 2; 
            lines.add(line);
        }
        
        scene.add(lines);
        return lines;
    }

    starField = createStarfield(); 
    neuralLines = createNeuralNetwork(500); 

    // --- 7. Content Creation Function (Unchanged) ---
    function createAndAttachContent(sectionKey) {
        if (contentObject) {
            scene.remove(contentObject);
            if (dataProbeObject) scene.remove(dataProbeObject); 
        }

        const data = CAMERA_POSITIONS[sectionKey];
        
        // 1. Create Main Content Card
        const element = document.createElement('div');
        element.className = 'content-card';
        element.innerHTML = data.html;
        contentElement = element; 

        element.style.transform = `translate(${data.offset[0]}, ${data.offset[1]}) scale(0.9) translateZ(-50px)`;
        element.style.transformOrigin = 'center center'; 

        const label = new CSS2DObject(element);
        label.position.copy(data.contentPos);
        contentObject = label;

        scene.add(contentObject);
    }
    
    // Function to create and show the temporary data probe panel (Unchanged)
    function createDataProbe(data) {
        if (dataProbeObject) scene.remove(dataProbeObject);

        const probeHTML = `
            <div>> INITIATING COGNITIVE PROBE: ${currentSection}</div>
            <div>> QUERY: FETCH\_SECTION\_DATA</div>
            <div>> STATUS: PROCESSING...</div>
            <div class="progress-bar"><div class="progress-fill" id="probe-fill"></div></div>
            <div style="margin-top: 10px; color: #99ccff;">> OUTPUT READY</div>
        `;

        const probeElement = document.createElement('div');
        probeElement.className = 'data-probe';
        probeElement.innerHTML = probeHTML;

        const probePos = data.contentPos.clone();
        probePos.x += 0.5; 
        probePos.y -= 0.5;

        const probeLabel = new CSS2DObject(probeElement);
        probeLabel.position.copy(probePos);
        dataProbeObject = probeLabel;

        scene.add(dataProbeObject);

        setTimeout(() => {
            probeElement.classList.add('ready');
            const fill = document.getElementById('probe-fill');
            if(fill) fill.style.width = '100%';
        }, 50); 
    }
    
    // --- 8. Load Brain (GLTF) ---
    const loader = new GLTFLoader();
    loader.load(
        './models/brain/scene.gltf', 
        (gltf) => {
            brain = gltf.scene;
            
            // NOTE: Material application removed to preserve original colors/textures.
            // The pulse will now be handled by scaling.

            // Centering logic
            const bbox = new THREE.Box3().setFromObject(brain);
            const center = bbox.getCenter(new THREE.Vector3());
            brain.position.sub(center); 

            brain.scale.set(BRAIN_SCALE, BRAIN_SCALE, BRAIN_SCALE); 
            scene.add(brain);
            
            // Content Initialization (for OVERVIEW)
            createAndAttachContent(currentSection);
            
            // Apply FINAL transform state for the initial OVERVIEW card
            const data = CAMERA_POSITIONS[currentSection];
            contentElement.style.transform = `translate(${data.offset[0]}, ${data.offset[1]}) scale(1) translateZ(0px)`;
            contentElement.classList.add('active'); 

            transitionInProgress = false; 
        },
        undefined,
        (err) => console.error('Error loading GLTF model:', err)
    );

    // --- 9. Cinematic & Animation Logic (The Core) ---
    function animate() {
        requestAnimationFrame(animate);

        // A. Cinematic Camera Transition 
        if (transitionInProgress) {
            camera.position.lerp(currentTarget.pos, LERP_FACTOR);
            controls.target.lerp(currentTarget.target, LERP_FACTOR);
            
            // NEW: Apply breathing pulse during navigation (visually indicates processing)
            if (brain) {
                pulseFactor += PULSE_SPEED;
                const pulseScale = BRAIN_SCALE + Math.sin(pulseFactor) * PULSE_MAGNITUDE; 
                brain.scale.set(pulseScale, pulseScale, pulseScale);
            }
            
            if (camera.position.distanceTo(currentTarget.pos) < 0.01) {
                // Camera stops
                transitionInProgress = false;
                
                // Reset pulse factor and scale to normal
                pulseFactor = 0.0;
                if (brain) brain.scale.set(BRAIN_SCALE, BRAIN_SCALE, BRAIN_SCALE);
                
                createDataProbe(currentTarget);
                
                setTimeout(() => {
                    controls.enabled = true;
                    
                    if(dataProbeObject) dataProbeObject.element.style.opacity = '0';
                    
                    const data = CAMERA_POSITIONS[currentSection];
                    contentElement.style.transform = `translate(${data.offset[0]}, ${data.offset[1]}) scale(1) translateZ(0px)`;
                    contentElement.classList.add('active'); 
                }, DATA_PROBE_DELAY); 
            }
        }
        
        // B. Idle Brain Animation & Background Animation
        if (brain) {
            // Idle rotation
            if (!transitionInProgress) {
                brain.rotation.y += 0.002;
            }
            
            if (neuralLines) {
                neuralLines.children.forEach(line => {
                    line.material.opacity = (Math.sin(time * 0.05 + line.userData.pulse) * 0.05) + 0.1;
                });
            }
            
            if (starField) {
                starField.rotation.y += 0.0001; 
            }
            
            time++;
        }

        // C. Update & Render
        controls.update(); 
        renderer.render(scene, camera); 
        labelRenderer.render(scene, camera); 
    }
    animate();

    // --- 10. Project Expansion Logic (Global Functions) ---
    // Function that opens the full screen modal and injects HTML content
    window.openExpandedCard = function(projectHtml) {
        const expandedCard = document.getElementById('expanded-project');
        const expandedContent = document.getElementById('expanded-content');
        
        expandedContent.innerHTML = projectHtml;
        
        expandedCard.classList.add('visible');
        
        controls.enabled = false;
    }

    // Function that closes the full screen modal
    window.closeExpandedCard = function() {
        const expandedCard = document.getElementById('expanded-project');
        
        expandedCard.classList.remove('visible');
        
        controls.enabled = true;
    }

    // Function that looks up the project content by key and calls the opener
    window.openProject = function(projectKey) {
        const projectHtml = PROJECT_DETAILS[projectKey];
        if (projectHtml) {
            window.openExpandedCard(projectHtml);
        } else {
            console.error('Error: Project data not found for key:', projectKey);
        }
    }


    // --- 11. Navigation Logic (Called by UI buttons) ---
    window.navigateTo = function(targetKey) {
        if (CAMERA_POSITIONS[targetKey] && !transitionInProgress && targetKey !== currentSection) {
            
            // 1. Hide Current Content & Data Probe
            if (contentElement) contentElement.classList.remove('active');
            if (dataProbeObject) dataProbeObject.element.style.opacity = '0'; 
            
            // 2. Set New Target & Start Transition
            currentTarget = CAMERA_POSITIONS[targetKey];
            currentSection = targetKey; 
            controls.enabled = false; 
            transitionInProgress = true;
            
            // 3. Create the new content object (it will be revealed after data probe delay)
            createAndAttachContent(targetKey); 
        }
    }
    
    document.getElementById('ui-menu').addEventListener('click', (event) => {
        const target = event.target.getAttribute('data-target');
        if (target) {
            window.navigateTo(target);
        }
    });

    // --- 12. Resize Handler ---
    window.addEventListener('resize', () => {
        camera.aspect = window.innerWidth / window.innerHeight;
        camera.updateProjectionMatrix();
        renderer.setSize(window.innerWidth, window.innerHeight);
        labelRenderer.setSize(window.innerWidth, window.innerHeight);
    });
</script>

</body>
</html>